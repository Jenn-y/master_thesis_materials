{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUPIL DATA\n",
    "\n",
    "Raw data visualization with trials indicated by vertical lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file_path = 'PupilData/PupilData_243356.csv'\n",
    "df = pd.read_csv('PupilData/PupilData_243356.csv', header=0, names=['Timestamp', 'Scene', 'LeftPupil(mm)', 'RightPupil(mm)', 'LeftValid', 'RightValid'])\n",
    "\n",
    "df.head()\n",
    "df['LeftPupil(mm)'] = pd.to_numeric(df['LeftPupil(mm)'], errors='coerce')\n",
    "df['RightPupil(mm)'] = pd.to_numeric(df['RightPupil(mm)'], errors='coerce')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['LeftPupil(mm)'], label='Left Pupil', color='skyblue')\n",
    "plt.plot(df['RightPupil(mm)'], label='Right Pupil', color='lightgreen')\n",
    "\n",
    "for i in range(1, len(df)):\n",
    "    if (df['Scene'].iloc[i-1] == 'AvatarSceneHappy' or df['Scene'].iloc[i-1] == 'AvatarSceneNeutral') and df['Scene'].iloc[i] == 'BaselineScene':\n",
    "        plt.axvline(x=i, color='r', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.title('Raw Pupil Traces of 243356')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Pupil Size (mm)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PUPIL DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking pupil data validity and correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data_folder = 'PupilData/'\n",
    "summary = []\n",
    "\n",
    "for file_path in glob(os.path.join(data_folder, 'PupilData_*.csv')):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        df['LeftPupil(mm)'] = pd.to_numeric(df['LeftPupil(mm)'], errors='coerce')\n",
    "        df['RightPupil(mm)'] = pd.to_numeric(df['RightPupil(mm)'], errors='coerce')\n",
    "        df['LeftValid'] = df['LeftValid'].astype(str).str.lower().map({'true': True, 'false': False})\n",
    "        df['RightValid'] = df['RightValid'].astype(str).str.lower().map({'true': True, 'false': False})\n",
    "\n",
    "        participant_id = os.path.basename(file_path).split('_')[1].replace('.csv', '')\n",
    "\n",
    "        left_valid_rate = df['LeftValid'].mean() * 100\n",
    "        right_valid_rate = df['RightValid'].mean() * 100\n",
    "\n",
    "        valid_data = df[df['LeftValid'] & df['RightValid']].copy()\n",
    "        valid_data = valid_data.replace(0, np.nan).dropna(subset=['LeftPupil(mm)', 'RightPupil(mm)'])\n",
    "\n",
    "        correlation = valid_data['LeftPupil(mm)'].corr(valid_data['RightPupil(mm)'])\n",
    "\n",
    "        summary.append({\n",
    "            'Participant': participant_id,\n",
    "            'Left Validity (%)': round(left_valid_rate, 2),\n",
    "            'Right Validity (%)': round(right_valid_rate, 2),\n",
    "            'Left-Right Correlation': round(correlation, 2) if not np.isnan(correlation) else None\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df.set_index('Participant', inplace=True)\n",
    "\n",
    "participants = summary_df.index.astype(str)\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(14, 14), gridspec_kw={'hspace': 0.4})\n",
    "\n",
    "# 1. Left vs Right Validity (Clustered Bar Chart)\n",
    "x = range(len(participants))\n",
    "bar_width = 0.35\n",
    "\n",
    "axs[0].bar(x, summary_df['Left Validity (%)'], width=bar_width, label='Left Validity', color='skyblue')\n",
    "axs[0].bar([i + bar_width for i in x], summary_df['Right Validity (%)'], width=bar_width, label='Right Validity', color='lightgreen')\n",
    "axs[0].axhline(95, color='red', linestyle='--', label='95% Threshold')\n",
    "axs[0].set_title('Validity of Pupil Data by Participant')\n",
    "axs[0].set_ylabel('Validity (%)')\n",
    "axs[0].set_xticks([i + bar_width / 2 for i in x])\n",
    "axs[0].set_xticklabels(participants, rotation=90)\n",
    "axs[0].legend()\n",
    "\n",
    "# 2. Left-Right Pupil Correlation (Bar Chart)\n",
    "axs[1].bar(participants, summary_df['Left-Right Correlation'], color='coral')\n",
    "axs[1].axhline(0.5, color='red', linestyle='--', label='Threshold (r=0.5)')\n",
    "axs[1].set_title('Correlation Between Left and Right Pupil Size')\n",
    "axs[1].set_ylabel('Pearson Correlation (r)')\n",
    "axs[1].legend()\n",
    "\n",
    "# 3. Scatter: Validity vs Correlation (Bubble Plot)\n",
    "sns.scatterplot(\n",
    "    data=summary_df.reset_index(),\n",
    "    x='Left Validity (%)',\n",
    "    y='Left-Right Correlation',\n",
    "    size='Right Validity (%)',\n",
    "    sizes=(50, 300),\n",
    "    hue='Right Validity (%)',\n",
    "    palette='viridis',\n",
    "    ax=axs[2]\n",
    ")\n",
    "axs[2].axhline(0.5, color='red', linestyle='--')\n",
    "axs[2].axvline(95, color='blue', linestyle='--')\n",
    "axs[2].set_title('Left Validity vs Correlation (Bubble = Right Validity)')\n",
    "axs[2].set_xlabel('Left Validity (%)')\n",
    "axs[2].set_ylabel('Left-Right Correlation')\n",
    "axs[2].legend(title='Right Validity (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing remaining 22 files (4 files excluded with the previous step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, savgol_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_left_eye_pupil(file_path, surrounding_ms=200, fs=10, plot=True):\n",
    "    # === Load and basic filtering ===\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['LeftValid'] = df['LeftValid'].astype(str).str.lower() == 'true'\n",
    "    df['LeftPupil(mm)'] = pd.to_numeric(df['LeftPupil(mm)'], errors='coerce')\n",
    "    df.loc[~df['LeftValid'], 'LeftPupil(mm)'] = np.nan\n",
    "    df_raw = df.copy()\n",
    "\n",
    "    # === Implausible values removed ===\n",
    "    df.loc[(df['LeftPupil(mm)'] < 1.5) | (df['LeftPupil(mm)'] > 7.0), 'LeftPupil(mm)'] = np.nan\n",
    "\n",
    "    # === Blink-surrounding trimming ===\n",
    "    surrounding = int((surrounding_ms / 1000) * fs)\n",
    "    blink_indices = df[df['LeftPupil(mm)'].isna()].index\n",
    "    for i in blink_indices:\n",
    "        df.loc[max(i - surrounding, 0):min(i + surrounding, len(df) - 1), 'LeftPupil(mm)'] = np.nan\n",
    "\n",
    "    # === Remove spikes & high acceleration ===\n",
    "    diff = df['LeftPupil(mm)'].diff().abs()\n",
    "    df.loc[diff > 0.5, 'LeftPupil(mm)'] = np.nan\n",
    "\n",
    "    accel = None\n",
    "    if not df.empty:\n",
    "        accel = df['LeftPupil(mm)'].diff().diff().abs()\n",
    "    \n",
    "    df.loc[accel > 0.3, 'LeftPupil(mm)'] = np.nan\n",
    "\n",
    "    # === Interpolation ===\n",
    "    df['LeftPupil(mm)'] = df['LeftPupil(mm)'].interpolate(method='spline', order=2, limit_direction='both')\n",
    "\n",
    "    # === Savitzky-Golay smoothing ===\n",
    "    df['LeftPupil(mm)'] = savgol_filter(df['LeftPupil(mm)'].fillna(method='pad'), window_length=5, polyorder=2)\n",
    "\n",
    "    # === Butterworth lowpass filtering (balanced) ===\n",
    "    def butter_lowpass_filter(data, cutoff=0.6, fs=10, order=3):\n",
    "        nyq = 0.5 * fs\n",
    "        normal_cutoff = cutoff / nyq\n",
    "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        return filtfilt(b, a, data)\n",
    "\n",
    "    df['LeftPupilFiltered(mm)'] = butter_lowpass_filter(df['LeftPupil(mm)'], cutoff=0.6, fs=fs)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        plt.plot(df_raw['LeftPupil(mm)'], label='Left Eye (Raw)', color='lightgreen')\n",
    "        plt.plot(df['LeftPupilFiltered(mm)'], label='Left Eye (Filtered)', color='coral')\n",
    "        plt.title('Left Eye Pupil Size – Filtered')\n",
    "        plt.xlabel('Sample Index')\n",
    "        plt.ylabel('Pupil Size (mm)')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return df\n",
    "\n",
    "folder_path = 'PupilData'\n",
    "\n",
    "all_files = [f for f in os.listdir(folder_path) if f.endswith('.csv') and '_corrupted' not in f and '_outlier' not in f]\n",
    "\n",
    "cleaned_data = {}\n",
    "for file in all_files:\n",
    "    participant_id = file.replace('.csv', '').split('_')[-1]\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "\n",
    "    try:\n",
    "        cleaned_df = preprocess_left_eye_pupil(file_path, plot=True, fs=10)\n",
    "        cleaned_data[participant_id] = cleaned_df\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping {file} due to error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BVP DATA\n",
    "\n",
    "Visualization of raw signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"../Trial1/243349.txt\",\n",
    "    skiprows=9,\n",
    "    header=None,\n",
    "    usecols=[0, 1, 2],\n",
    "    names=['min', 'CH1', 'CH40']\n",
    ")\n",
    "\n",
    "df['min'] = df['min'].astype(float)\n",
    "df['time_sec'] = df['min'] * 60\n",
    "\n",
    "plt.figure(figsize=(15, 4))\n",
    "plt.plot(df['time_sec'], df['CH1'], lw=0.5, color='red')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('PPG (Volts)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing with neurokit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "import re\n",
    "\n",
    "\n",
    "parent_dir = \"./PulseData\"\n",
    "trial_types = [\"BaselineAnxietyHappy\", \"BaselineAnxietyNeutral\", \"BaselineNeutralHappy\", \"BaselineNeutralNeutral\"]\n",
    "\n",
    "def process_ppg_file(filepath, trial_type, participant_id, show_plot=False):\n",
    "    df = pd.read_csv(\n",
    "        filepath,\n",
    "        skiprows=9,\n",
    "        header=None,\n",
    "        usecols=[0, 1, 2],\n",
    "        names=['min', 'CH1', 'CH40']\n",
    "    )\n",
    "    df['min'] = df['min'].astype(float)\n",
    "    df['time_sec'] = df['min'] * 60\n",
    "\n",
    "    fs = 2000\n",
    "    raw_signal = df['CH1'].values\n",
    "    time = df['time_sec'].values\n",
    "\n",
    "    TRIM_SEC = 3\n",
    "    start_time = time[0] + TRIM_SEC\n",
    "    end_time = time[-1] - TRIM_SEC\n",
    "    mask = (time >= start_time) & (time <= end_time)\n",
    "    time_trimmed = time[mask]\n",
    "    signal_trimmed = raw_signal[mask]\n",
    "\n",
    "    try:\n",
    "        plt.rcParams['figure.figsize'] = (12, 8)  # Wider and taller\n",
    "        signals, info = nk.ppg_process(signal_trimmed, sampling_rate=fs, report=\"test.html\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing full signal: {e}\")\n",
    "        return None\n",
    "\n",
    "    if show_plot:\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        plt.plot(time_trimmed, signal_trimmed, alpha=0.4, label=\"Raw Trimmed\")\n",
    "        plt.plot(time_trimmed, signals['PPG_Clean'], label=\"PPG Clean\", linewidth=1)\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"PPG\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Full PPG Signal (Cleaned)\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    baseline_start = start_time\n",
    "    baseline_end = start_time + 60\n",
    "    task_start = baseline_end\n",
    "    task_end = end_time - 30\n",
    "    avatar_start = task_end\n",
    "    avatar_end = end_time\n",
    "\n",
    "    def get_mask(scene_start, scene_end, trim_start=True, trim_end=True, trim_sec=3):\n",
    "        start = scene_start + (trim_sec if trim_start else 0)\n",
    "        end = scene_end - (trim_sec if trim_end else 0)\n",
    "        return (time_trimmed >= start) & (time_trimmed < end)\n",
    "\n",
    "    mask_baseline = get_mask(baseline_start, baseline_end, trim_start=False, trim_end=True)\n",
    "    mask_task = get_mask(task_start, task_end, trim_start=True, trim_end=True)\n",
    "    mask_avatar = get_mask(avatar_start, avatar_end, trim_start=True, trim_end=False)\n",
    "\n",
    "    # === 5. Calculate HR & RMSSD from PPG_Rate ===\n",
    "    def compute_hrv_metrics(rate_series, sampling_rate=fs):\n",
    "        if rate_series.empty or len(rate_series) < sampling_rate * 5 / 1000:\n",
    "            return {\"HR_mean\": np.nan, \"RMSSD\": np.nan, \"SDNN\": np.nan}\n",
    "        rate_series = rate_series.dropna()\n",
    "        if rate_series.empty:\n",
    "            return {\"HR_mean\": np.nan, \"RMSSD\": np.nan, \"SDNN\": np.nan}\n",
    "        \n",
    "        hrv_df = nk.hrv(info, sampling_rate=sampling_rate, show=False)\n",
    "        return {\n",
    "            \"HR_mean\": rate_series.mean(),\n",
    "            \"RMSSD\": hrv_df[\"HRV_RMSSD\"].values[0] if \"HRV_RMSSD\" in hrv_df else np.nan,\n",
    "            \"SDNN\": hrv_df[\"HRV_SDNN\"].values[0] if \"HRV_SDNN\" in hrv_df else np.nan\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        hrv_baseline = compute_hrv_metrics(signals['PPG_Rate'][mask_baseline])\n",
    "        hrv_task = compute_hrv_metrics(signals['PPG_Rate'][mask_task])\n",
    "        hrv_avatar = compute_hrv_metrics(signals['PPG_Rate'][mask_avatar])\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error computing HRV per segment: {e}\")\n",
    "        return None\n",
    "\n",
    "    trial_parts = re.split(r'(?=[A-Z])', trial_type)\n",
    "    task_type = trial_parts[2] + \"Scene\"\n",
    "    avatar_type = \"AvatarScene\" + trial_parts[3]\n",
    "\n",
    "    summary = {\n",
    "        \"participant\": participant_id,\n",
    "        \"trial_type\": trial_type,\n",
    "        \"task_type\": task_type,\n",
    "        \"avatar_type\": avatar_type,\n",
    "        \"baseline_HR\": hrv_baseline[\"HR_mean\"],\n",
    "        \"baseline_SDNN\": hrv_baseline[\"SDNN\"],\n",
    "        \"baseline_RMSSD\": hrv_baseline[\"RMSSD\"],\n",
    "        \"task_HR\": hrv_task[\"HR_mean\"],\n",
    "        \"task_SDNN\": hrv_task[\"SDNN\"],\n",
    "        \"task_RMSSD\": hrv_task[\"RMSSD\"],\n",
    "        \"avatar_HR\": hrv_avatar[\"HR_mean\"],\n",
    "        \"avatar_SDNN\": hrv_avatar[\"SDNN\"],\n",
    "        \"avatar_RMSSD\": hrv_avatar[\"RMSSD\"],\n",
    "        \"delta_HR_task_minus_baseline\": hrv_task[\"HR_mean\"] - hrv_baseline[\"HR_mean\"] if pd.notna(hrv_task[\"HR_mean\"]) and pd.notna(hrv_baseline[\"HR_mean\"]) else np.nan,\n",
    "        \"delta_HR_avatar_minus_task\": hrv_avatar[\"HR_mean\"] - hrv_task[\"HR_mean\"] if pd.notna(hrv_avatar[\"HR_mean\"]) and pd.notna(hrv_task[\"HR_mean\"]) else np.nan,\n",
    "        \"delta_RMSSD_task_minus_baseline\": hrv_task[\"RMSSD\"] - hrv_baseline[\"RMSSD\"] if pd.notna(hrv_task[\"RMSSD\"]) and pd.notna(hrv_baseline[\"RMSSD\"]) else np.nan,\n",
    "        \"delta_RMSSD_avatar_minus_task\": hrv_avatar[\"RMSSD\"] - hrv_task[\"RMSSD\"] if pd.notna(hrv_avatar[\"RMSSD\"]) and pd.notna(hrv_task[\"RMSSD\"]) else np.nan\n",
    "    }\n",
    "\n",
    "    return summary\n",
    "\n",
    "# --- Batch processing ---\n",
    "summary_list = []\n",
    "for trial_type in trial_types:\n",
    "    folder = os.path.join(parent_dir, trial_type)\n",
    "    if not os.path.exists(folder):\n",
    "        print(folder + \" does not exist\")\n",
    "        continue\n",
    "    for fname in os.listdir(folder):\n",
    "        if not fname.endswith('.txt'):\n",
    "            continue\n",
    "        participant_id = fname.replace('.txt', '')[:6]\n",
    "        \n",
    "        filepath = os.path.join(folder, fname)\n",
    "        print(f\"Processing {filepath} ...\")\n",
    "        summary = process_ppg_file(filepath, trial_type, participant_id, show_plot=True)\n",
    "        summary_list.append(summary)\n",
    "\n",
    "# --- Save summary DataFrame ---\n",
    "summary_df = pd.DataFrame(summary_list)\n",
    "summary_df.to_csv(\"ppg_summary_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STAI-S SCORES CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "input_csv = 'Experiment1 - Form Responses.csv'\n",
    "output_csv = 'STAI_Scores.csv'\n",
    "\n",
    "score_map = {\n",
    "    '全くない / Not at all': 1,\n",
    "    '少しある / Somewhat': 2,\n",
    "    'かなりある / Moderately so': 3,\n",
    "    '非常にある / Very much so': 4\n",
    "}\n",
    "\n",
    "reverse_scored_items = [1, 2, 5, 8, 10, 11, 15, 16, 19, 20]\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(input_csv)\n",
    "    output_data = {'ParticipantID': df['学生ID / StudentID']}\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        stai_columns = {}\n",
    "        for col in df.columns:\n",
    "            match = re.match(rf'STAI-S #{i} \\[(.+?)\\s*/\\s*(.+?)\\]', col)\n",
    "            if match:\n",
    "                english_text = match.group(2).strip()\n",
    "                item_mapping_text_to_number = {\n",
    "                    \"I feel calm.\": 1,\n",
    "                    \"I feel secure.\": 2,\n",
    "                    \"I am tense.\": 3,\n",
    "                    \"I feel strained.\": 4,\n",
    "                    \"I feel at ease.\": 5,\n",
    "                    \"I feel upset.\": 6,\n",
    "                    \"I am worrying over possible misfortunes.\": 7,\n",
    "                    \"I feel satisfied.\": 8,\n",
    "                    \"I feel frightened.\": 9,\n",
    "                    \"I feel comfortable.\": 10,\n",
    "                    \"I feel self-confident.\": 11,\n",
    "                    \"I feel nervous.\": 12,\n",
    "                    \"I am jittery.\": 13,\n",
    "                    \"I feel indecisive.\": 14,\n",
    "                    \"I am relaxed.\": 15,\n",
    "                    \"I feel content.\": 16,\n",
    "                    \"I am worried.\": 17,\n",
    "                    \"I feel confused.\": 18,\n",
    "                    \"I feel steady.\": 19,\n",
    "                    \"I feel pleasant.\": 20\n",
    "                }\n",
    "                item_number = item_mapping_text_to_number.get(english_text)\n",
    "                if item_number is not None:\n",
    "                     stai_columns[col] = item_number\n",
    "\n",
    "        stai_df = df[list(stai_columns.keys())].copy()\n",
    "\n",
    "        stai_df.replace(score_map, inplace=True)\n",
    "\n",
    "        for col, item_num in stai_columns.items():\n",
    "            if item_num in reverse_scored_items:\n",
    "                stai_df[col] = 5 - stai_df[col]\n",
    "\n",
    "        output_data[f'STAI-S Score {i}'] = stai_df.sum(axis=1)\n",
    "\n",
    "    stai_df = pd.DataFrame(output_data)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Input file not found at {input_csv}\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Missing expected column in {input_csv}: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate participants into anxiety grous based on baseline STAI-S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_scores = stai_df\n",
    "    median_stai_score_1 = df_scores['STAI-S Score 1'].median()\n",
    "\n",
    "    print(f\"Median STAI-S Score 1: {median_stai_score_1}\")\n",
    "\n",
    "    df_scores['Anxiety_Group'] = df_scores['STAI-S Score 1'].apply(\n",
    "        lambda score: 'Higher Anxiety' if score > median_stai_score_1 else 'Lower Anxiety'\n",
    "    )\n",
    "\n",
    "    print(\"\\nDataFrame with Anxiety Groups:\")\n",
    "    print(df_scores.head())\n",
    "    df_scores.to_csv('STAI_Scores_with_Groups.csv', index=False)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Input file not found at {input_csv}\")\n",
    "except KeyError as e:\n",
    "    print(f\"Error: Missing expected column in {input_csv}: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN ANALYSIS\n",
    "\n",
    "Anxiety validation by pupil data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "\n",
    "def classify_phase(scene_name):\n",
    "    if \"BaselineScene\" in scene_name:\n",
    "        return \"Baseline\", None\n",
    "    elif \"AnxietyScene\" in scene_name:\n",
    "        return \"Scene\", \"Anxiety\"\n",
    "    elif \"NeutralScene\" in scene_name:\n",
    "        return \"Scene\", \"NeutralScene\"\n",
    "    elif \"AvatarSceneHappy\" in scene_name:\n",
    "        return \"Avatar\", \"Happy\"\n",
    "    elif \"AvatarSceneNeutral\" in scene_name:\n",
    "        return \"Avatar\", \"Neutral\"\n",
    "    return \"Other\", None\n",
    "\n",
    "scene_counters = defaultdict(int)\n",
    "trial_metrics = []\n",
    "\n",
    "trial_metrics = []\n",
    "\n",
    "for participant_id, df in cleaned_data.items():\n",
    "    current_trial = None\n",
    "    current_phase = None\n",
    "    trial_num = 1\n",
    "    \n",
    "    baseline_data = []\n",
    "    scene_data = []\n",
    "    avatar_data = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        scene = row['Scene']\n",
    "        pupil_size = row['LeftPupilFiltered(mm)']\n",
    "        \n",
    "        scene_type, condition = classify_phase(scene)\n",
    "        \n",
    "        # Case 1: Baseline scene starts a new trial\n",
    "        if scene_type == \"Baseline\":\n",
    "            if current_phase == \"Avatar\":\n",
    "                # Save completed trial\n",
    "                if baseline_data and scene_data and avatar_data:\n",
    "                    trial_metrics.append({\n",
    "                        \"Participant\": participant_id,\n",
    "                        \"Trial\": trial_num,\n",
    "                        \"SceneType\": \"Anxiety\" if \"Anxiety\" in scene_data[0]['scene'] else \"Neutral\",\n",
    "                        \"AvatarType\": \"Happy\" if \"Happy\" in avatar_data[0]['scene'] else \"Neutral\",\n",
    "                        \"BaselineMean\": np.mean([d['pupil'] for d in baseline_data]),\n",
    "                        \"SceneMean\": np.mean([d['pupil'] for d in scene_data]),\n",
    "                        \"AvatarMean\": np.mean([d['pupil'] for d in avatar_data]),\n",
    "                        \"SceneΔ\": np.mean([d['pupil'] for d in scene_data]) - np.mean([d['pupil'] for d in baseline_data]),\n",
    "                        \"AvatarΔ\": np.mean([d['pupil'] for d in avatar_data]) - np.mean([d['pupil'] for d in baseline_data]),\n",
    "                        \"Scene→AvatarΔ\": np.mean([d['pupil'] for d in avatar_data]) - np.mean([d['pupil'] for d in scene_data]),\n",
    "                        \"BaselineDuration\": len(baseline_data),\n",
    "                        \"SceneDuration\": len(scene_data),\n",
    "                        \"AvatarDuration\": len(avatar_data)\n",
    "                    })\n",
    "                    trial_num += 1\n",
    "                \n",
    "                # Reset for new trial\n",
    "                baseline_data = []\n",
    "                scene_data = []\n",
    "                avatar_data = []\n",
    "            \n",
    "            current_phase = \"Baseline\"\n",
    "            baseline_data.append({\"scene\": scene, \"pupil\": pupil_size})\n",
    "        \n",
    "        # Case 2: Anxiety/Neutral scene (only record if we're in a trial)\n",
    "        elif scene_type == \"Scene\" and current_phase in [\"Baseline\", \"Scene\"]:\n",
    "            current_phase = \"Scene\"\n",
    "            scene_data.append({\"scene\": scene, \"pupil\": pupil_size})\n",
    "        \n",
    "        # Case 3: Avatar scene (only record if we were just in Scene phase)\n",
    "        elif scene_type == \"Avatar\" and current_phase == \"Scene\":\n",
    "            current_phase = \"Avatar\"\n",
    "            avatar_data.append({\"scene\": scene, \"pupil\": pupil_size})\n",
    "        \n",
    "    \n",
    "    if baseline_data and scene_data and avatar_data:\n",
    "        trial_metrics.append({\n",
    "            \"Participant\": participant_id,\n",
    "            \"Trial\": trial_num,\n",
    "            \"SceneType\": \"Anxiety\" if \"Anxiety\" in scene_data[0]['scene'] else \"Neutral\",\n",
    "            \"AvatarType\": \"Happy\" if \"Happy\" in avatar_data[0]['scene'] else \"Neutral\",\n",
    "            \"BaselineMean\": np.mean([d['pupil'] for d in baseline_data]),\n",
    "            \"SceneMean\": np.mean([d['pupil'] for d in scene_data]),\n",
    "            \"AvatarMean\": np.mean([d['pupil'] for d in avatar_data]),\n",
    "            \"SceneΔ\": np.mean([d['pupil'] for d in scene_data]) - np.mean([d['pupil'] for d in baseline_data]),\n",
    "            \"AvatarΔ\": np.mean([d['pupil'] for d in avatar_data]) - np.mean([d['pupil'] for d in baseline_data]),\n",
    "            \"Scene→AvatarΔ\": np.mean([d['pupil'] for d in avatar_data]) - np.mean([d['pupil'] for d in scene_data]),\n",
    "            \"BaselineDuration\": len(baseline_data),\n",
    "            \"SceneDuration\": len(scene_data),\n",
    "            \"AvatarDuration\": len(avatar_data)\n",
    "        })\n",
    "\n",
    "trial_df = pd.DataFrame(trial_metrics)\n",
    "df = trial_df\n",
    "df['Participant'] = df['Participant'].astype('category')\n",
    "df['SceneType'] = df['SceneType'].astype('category')\n",
    "df['AvatarType'] = df['AvatarType'].astype('category')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='SceneType', y='SceneΔ', data=df, palette='Set2')\n",
    "sns.stripplot(x='SceneType', y='SceneΔ', data=df, color='black', alpha=0.5, jitter=True)\n",
    "plt.title('Pupil Dilation (Scene – Baseline) by Scene Type')\n",
    "plt.ylabel('SceneΔ (mm)')\n",
    "plt.xlabel('Scene Type')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_df['AppearanceOrder'] = trial_df.groupby(['Participant', 'SceneType'])['Trial'].rank()\n",
    "trial_df['AppearanceOrder'] = trial_df['AppearanceOrder'].map({1: 'First', 2: 'Second'})\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(\n",
    "    x='SceneType',\n",
    "    y='SceneΔ',\n",
    "    hue='AppearanceOrder',\n",
    "    data=trial_df,\n",
    "    palette={'First': '#1f77b4', 'Second': '#ff7f0e'},\n",
    "    whis=1.5\n",
    ")\n",
    "plt.title('Pupil Dilation by Scene Type and Exposure Order')\n",
    "plt.ylabel('Δ Pupil Size (mm)')\n",
    "plt.xlabel('Scene Type')\n",
    "plt.legend(title='Exposure Order')\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical analysis of Task Scene Type in Pupil Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "from scipy.stats import mannwhitneyu\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "first_exposure = trial_df[trial_df['AppearanceOrder']=='First'].groupby('Participant')['SceneΔ'].mean()\n",
    "second_exposure = trial_df[trial_df['AppearanceOrder']=='Second'].groupby('Participant')['SceneΔ'].mean()\n",
    "print(wilcoxon(first_exposure, second_exposure))\n",
    "\n",
    "anxiety = trial_df[trial_df['SceneType'] == 'Anxiety']['SceneΔ']\n",
    "neutral = trial_df[trial_df['SceneType'] == 'Neutral']['SceneΔ']\n",
    "wilcoxon(anxiety, neutral)\n",
    "\n",
    "def rank_biserial(x, y):\n",
    "    u_stat = mannwhitneyu(x, y).statistic\n",
    "    n1, n2 = len(x), len(y)\n",
    "    return 1 - (2 * u_stat / (n1 * n2))  # r = 1 - (2U/nm)\n",
    "\n",
    "r = rank_biserial(anxiety, neutral)\n",
    "print(f\"Rank-Biserial r = {r:.3f}\")\n",
    "\n",
    "def cohens_d(x, y):\n",
    "    nx, ny = len(x), len(y)\n",
    "    pooled_std = np.sqrt(((nx-1)*np.std(x, ddof=1)**2 + (ny-1)*np.std(y, ddof=1)**2) / (nx + ny - 2))\n",
    "    return (np.mean(x) - np.mean(y)) / pooled_std\n",
    "\n",
    "print(\"Cohen’s d (Anxiety vs. Neutral):\", cohens_d(anxiety, neutral))\n",
    "\n",
    "model = smf.mixedlm(\"SceneΔ ~ SceneType\", data=trial_df, \n",
    "                    groups=trial_df[\"Participant\"]).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anxiety validation by pulse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "df = summary_df\n",
    "\n",
    "anxiety_group = df[df['task_type'] == 'AnxietyScene']\n",
    "neutral_group = df[df['task_type'] == 'NeutralScene']\n",
    "\n",
    "print(\"Mean HR increase (Anxiety):\", anxiety_group['delta_HR_task_minus_baseline'].mean())\n",
    "print(\"Mean HR increase (Neutral):\", neutral_group['delta_HR_task_minus_baseline'].mean())\n",
    "\n",
    "print(\"Mean RMSSD change (Anxiety):\", anxiety_group['delta_RMSSD_task_minus_baseline'].mean())\n",
    "print(\"Mean RMSSD change (Neutral):\", neutral_group['delta_RMSSD_task_minus_baseline'].mean())\n",
    "\n",
    "print(\"Mean SDNN change (Anxiety):\", (anxiety_group['task_SDNN'] - anxiety_group['baseline_SDNN']).mean())\n",
    "print(\"Mean SDNN change (Neutral):\", (neutral_group['task_SDNN'] - neutral_group['baseline_SDNN']).mean())\n",
    "\n",
    "t_stat, p_val = ttest_rel(\n",
    "    anxiety_group['delta_HR_task_minus_baseline'].dropna(),\n",
    "    neutral_group['delta_HR_task_minus_baseline'].dropna()\n",
    ")\n",
    "print(f\"Paired t-test: t={t_stat:.2f}, p={p_val:.3f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "boxprops = dict(linestyle='-', linewidth=2, color='skyblue')\n",
    "medianprops = dict(linestyle='-', linewidth=0.5, color='red')\n",
    "whiskerprops = dict(linestyle='--', linewidth=1.5, color='#2ca02c')\n",
    "\n",
    "bp = plt.boxplot([\n",
    "    anxiety_group['delta_HR_task_minus_baseline'].dropna(),\n",
    "    neutral_group['delta_HR_task_minus_baseline'].dropna()\n",
    "], \n",
    "labels=['Anxiety', 'Neutral'],\n",
    "patch_artist=True,\n",
    "boxprops=dict(facecolor='skyblue', **boxprops),\n",
    "medianprops=medianprops,\n",
    "capprops=dict(linewidth=2),\n",
    "widths=0.6)\n",
    "\n",
    "for i, group in enumerate([anxiety_group, neutral_group]):\n",
    "    y = group['delta_HR_task_minus_baseline'].dropna()\n",
    "    x = np.random.normal(i+1, 0.04, size=len(y))\n",
    "    plt.plot(x, y, 'o', color='#7f7f7f', alpha=0.6, markersize=8, markeredgewidth=0.5, markeredgecolor='white')\n",
    "\n",
    "plt.ylabel('HR Change (bpm)\\nTask Scene - Baseline', fontsize=12, labelpad=10)\n",
    "plt.xlabel('Scene Type', fontsize=12, labelpad=10)\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVATAR EFFECTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = trial_df\n",
    "\n",
    "# === Boxplot: Scene→AvatarΔ by AvatarType ===\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='AvatarType', y='Scene→AvatarΔ', data=df, palette='Set2')\n",
    "sns.stripplot(x='AvatarType', y='Scene→AvatarΔ', data=df, color='black', alpha=0.5, jitter=True)\n",
    "plt.title('Pupil Change (Avatar – Scene) by Avatar Type')\n",
    "plt.ylabel('Scene→AvatarΔ (mm)')\n",
    "plt.xlabel('Avatar Type')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Lineplot: Each participant's 4 trials ===\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df, x='Trial', y='Scene→AvatarΔ', hue='Participant', marker='o', legend=False)\n",
    "plt.title('Within-Subject Change from Scene to Avatar')\n",
    "plt.ylabel('Scene→AvatarΔ (mm)')\n",
    "plt.xlabel('Trial')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='SceneType', y='Scene→AvatarΔ', hue='AvatarType', data=df, ci='sd')\n",
    "plt.title('Scene × Avatar Interaction on Pupil Change (Avatar – Scene)')\n",
    "plt.ylabel('Δ Pupil Size (mm)')\n",
    "plt.xlabel('Scene Type')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "\n",
    "happy = df[df['AvatarType'] == 'Happy']['Scene→AvatarΔ']\n",
    "neutral = df[df['AvatarType'] == 'Neutral']['Scene→AvatarΔ']\n",
    "print(len(happy))\n",
    "print(len(neutral))\n",
    "\n",
    "t_stat, p_val = ttest_rel(happy, neutral)\n",
    "print(f\"Paired t-test: t={t_stat:.2f}, p={p_val:.3f}\")\n",
    "\n",
    "w_stat, w_p = wilcoxon(happy, neutral)\n",
    "print(f\"Wilcoxon: stat={w_stat}, p={w_p:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = summary_df\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(\n",
    "    x='task_type',\n",
    "    y='delta_HR_avatar_minus_task',\n",
    "    hue='avatar_type',\n",
    "    data=df,\n",
    "    palette='Set3'\n",
    ")\n",
    "plt.xlabel('Task Type')\n",
    "plt.ylabel('HR Reduction (Avatar - Task)')\n",
    "plt.legend(title='Avatar Type')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "\n",
    "happy = df[df['avatar_type'] == 'AvatarSceneHappy']\n",
    "neutral = df[df['avatar_type'] == 'AvatarSceneNeutral']\n",
    "\n",
    "print(\"Mean HR reduction (Happy avatar):\", happy['delta_HR_avatar_minus_task'].mean())\n",
    "print(\"Mean HR reduction (Neutral avatar):\", neutral['delta_HR_avatar_minus_task'].mean())\n",
    "\n",
    "print(\"Mean RMSSD change (Anxiety):\", happy['delta_RMSSD_avatar_minus_task'].mean())\n",
    "print(\"Mean RMSSD change (Neutral):\", neutral['delta_RMSSD_avatar_minus_task'].mean())\n",
    "\n",
    "print(\"Mean SDNN change (Anxiety):\", (happy['avatar_SDNN'] - happy['task_SDNN']).mean())\n",
    "print(\"Mean SDNN change (Neutral):\", (neutral['avatar_SDNN'] - neutral['task_SDNN']).mean())\n",
    "\n",
    "t, p = ttest_rel(\n",
    "    happy['delta_HR_avatar_minus_task'].values,\n",
    "    neutral['delta_HR_avatar_minus_task'].values\n",
    ")\n",
    "print(f\"Paired t-test: t={t:.2f}, p={p:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis by anxiety groups based on initial STAI-S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stai_df = pd.read_csv('STAI_Scores_with_Groups.csv') \n",
    "stai_df['ParticipantID'] = stai_df['ParticipantID'].astype(str)\n",
    "\n",
    "merged_dfs = []\n",
    "\n",
    "for pid, df in cleaned_data.items():\n",
    "    df = df.copy()\n",
    "    df['ParticipantID'] = pid\n",
    "    df = df.merge(stai_df[['ParticipantID', 'Anxiety_Group']], on='ParticipantID', how='left')\n",
    "    merged_dfs.append(df)\n",
    "\n",
    "full_df = pd.concat(merged_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "BASELINE_SCENE = 'BaselineScene'\n",
    "TASK_SCENES = ['AnxietyScene', 'NeutralScene']\n",
    "AVATAR_SCENES = ['AvatarSceneHappy', 'AvatarSceneNeutral']\n",
    "\n",
    "def assign_trial_numbers(df):\n",
    "    df = df.copy()\n",
    "    df['Trial'] = -1\n",
    "    trial = -1\n",
    "    prev_scene = None\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['Scene'] == 'BaselineScene' and prev_scene != 'BaselineScene':\n",
    "            trial += 1\n",
    "        df.at[idx, 'Trial'] = trial\n",
    "        prev_scene = row['Scene']\n",
    "    return df\n",
    "\n",
    "full_df = full_df.groupby('ParticipantID', group_keys=False).apply(assign_trial_numbers)\n",
    "\n",
    "trial_summaries = []\n",
    "\n",
    "for (pid, trial), group in full_df.groupby(['ParticipantID', 'Trial']):\n",
    "    anxiety_group = group['Anxiety_Group'].iloc[0]\n",
    "\n",
    "    stai_row = stai_df[stai_df['ParticipantID'] == str(pid)]\n",
    "    if stai_row.empty or trial < 0 or trial >= 4:\n",
    "        continue\n",
    "\n",
    "    pre_stai = stai_row[f'STAI-S Score {trial+1}'].values[0]\n",
    "    post_stai = stai_row[f'STAI-S Score {trial+2}'].values[0]\n",
    "    stai_change = post_stai - pre_stai\n",
    "    \n",
    "    scenes = group['Scene'].unique()\n",
    "    # Extract baseline, task, and avatar scenes\n",
    "    baseline = group[group['Scene'] == BASELINE_SCENE]['LeftPupilFiltered(mm)']\n",
    "    task = group[group['Scene'].isin(TASK_SCENES)]['LeftPupilFiltered(mm)']\n",
    "    avatar = group[group['Scene'].isin(AVATAR_SCENES)]['LeftPupilFiltered(mm)']\n",
    "    \n",
    "    task_type = group[group['Scene'].isin(TASK_SCENES)]['Scene'].iloc[0] if not task.empty else None\n",
    "    avatar_type = group[group['Scene'].isin(AVATAR_SCENES)]['Scene'].iloc[0] if not avatar.empty else None\n",
    "    \n",
    "    baseline_mean = baseline.mean() if not baseline.empty else None\n",
    "    task_mean = task.mean() if not task.empty else None\n",
    "    avatar_mean = avatar.mean() if not avatar.empty else None\n",
    "\n",
    "    task_change = task_mean - baseline_mean if task_mean is not None and baseline_mean is not None else None\n",
    "    avatar_change = avatar_mean - baseline_mean if avatar_mean is not None and baseline_mean is not None else None\n",
    "\n",
    "    trial_summaries.append({\n",
    "        'ParticipantID': pid,\n",
    "        'Anxiety_Group': anxiety_group,\n",
    "        'Trial': trial,\n",
    "        'TaskType': task_type,\n",
    "        'AvatarType': avatar_type,\n",
    "        'BaselineMean': baseline_mean,\n",
    "        'TaskMean': task_mean,\n",
    "        'AvatarMean': avatar_mean,\n",
    "        'TaskChange': task_change,\n",
    "        'AvatarChange': avatar_change,\n",
    "        'STAI_Pre': pre_stai,\n",
    "        'STAI_Post': post_stai,\n",
    "        'STAI_Change': stai_change\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(trial_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df['AvatarShift'] = summary_df['AvatarMean'] - summary_df['TaskMean']\n",
    "summary_df.to_csv(\"summary_group_pupil.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(\n",
    "    x='AvatarType',\n",
    "    y='AvatarChange',\n",
    "    hue='Anxiety_Group',\n",
    "    data=summary_df\n",
    ")\n",
    "plt.title(\"Pupil Change (AvatarChange) by Avatar Type and Anxiety Group\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# For AvatarShift\n",
    "model_avatarshift = smf.mixedlm(\n",
    "    \"AvatarShift ~ AvatarType * TaskType * Anxiety_Group\",\n",
    "    data=summary_df,\n",
    "    groups=summary_df[\"ParticipantID\"]\n",
    ")\n",
    "result_avatarshift = model_avatarshift.fit(method='nm')\n",
    "print(result_avatarshift.summary())\n",
    "\n",
    "# For STAI_Change\n",
    "model_staichange = smf.mixedlm(\n",
    "    \"STAI_Change ~ AvatarType * TaskType * Anxiety_Group\",\n",
    "    data=summary_df,\n",
    "    groups=summary_df[\"ParticipantID\"]\n",
    ")\n",
    "result_staichange = model_staichange.fit(method='lbfgs')\n",
    "print(result_staichange.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.boxplot(x='Anxiety_Group', y='AvatarShift', data=summary_df)\n",
    "sns.stripplot(x='Anxiety_Group', y='AvatarShift', data=summary_df, color='k', alpha=0.4, jitter=0.2)\n",
    "plt.title('Avatar Shift by Anxiety Group')\n",
    "plt.ylabel('Avatar Shift (AvatarMean - TaskMean)')\n",
    "plt.xlabel('Anxiety Group')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.pointplot(\n",
    "    x='AvatarType',\n",
    "    y='STAI_Change',\n",
    "    hue='TaskType',\n",
    "    data=summary_df,\n",
    "    dodge=True,\n",
    "    capsize=.1,\n",
    "    errwidth=1,\n",
    "    palette='Set2'\n",
    ")\n",
    "plt.title('STAI Change by Avatar Type and Task Type')\n",
    "plt.ylabel('STAI Change')\n",
    "plt.xlabel('Avatar Type')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.pointplot(\n",
    "    x='TaskType',\n",
    "    y='STAI_Change',\n",
    "    hue='Anxiety_Group',\n",
    "    data=summary_df,\n",
    "    dodge=True,\n",
    "    capsize=.1,\n",
    "    errwidth=1,\n",
    "    palette='Set1'\n",
    ")\n",
    "plt.title('STAI Change by Task Type and Anxiety Group')\n",
    "plt.ylabel('STAI Change')\n",
    "plt.xlabel('Task Type')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file1 = pd.read_csv(\"summary_group_pupil.csv\") \n",
    "file2 = pd.read_csv(\"ppg_summary_results.csv\")\n",
    "\n",
    "merged = pd.merge(\n",
    "    file1,\n",
    "    file2,\n",
    "    how='left',\n",
    "    left_on=['ParticipantID', 'TaskType', 'AvatarType'],\n",
    "    right_on=['participant', 'task_type', 'avatar_type']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dython.nominal import associations\n",
    "\n",
    "subset = df[['Anxiety_Group', 'TaskType', 'AvatarType', 'STAI_Pre', 'STAI_Post', 'STAI_Change',\n",
    "    'TaskChange', 'AvatarChange',\n",
    "    'baseline_HR', 'task_HR', 'avatar_HR',\n",
    "    'baseline_RMSSD', 'task_RMSSD', 'avatar_RMSSD',\n",
    "    'delta_HR_task_minus_baseline', 'delta_RMSSD_task_minus_baseline',]]\n",
    "\n",
    "associations(subset, cmap='coolwarm', nominal_columns=['Anxiety_Group', 'TaskType', 'AvatarType'], numerical_columns=['STAI_Pre', 'STAI_Post', 'STAI_Change',\n",
    "    'TaskChange', 'AvatarChange',\n",
    "    'baseline_HR', 'task_HR', 'avatar_HR',\n",
    "    'baseline_RMSSD', 'task_RMSSD', 'avatar_RMSSD',\n",
    "    'delta_HR_task_minus_baseline', 'delta_RMSSD_task_minus_baseline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IPQ Results and Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Experiment1 - Form Responses.csv\")\n",
    "\n",
    "question_phrases = [\n",
    "    \"I had the feeling that I was actually there\",\n",
    "    \"I felt surrounded by the virtual environment\",\n",
    "    \"I had the feeling that I was just watching pictures\",  \n",
    "    \"I did not feel present in the virtual space\",           \n",
    "    \"I was not just operating something externally\",\n",
    "    \"I had the impression of being in the middle of the action\",\n",
    "    \"how much were you aware of the real world\",            \n",
    "    \"I was no longer aware of my real environment\",\n",
    "    \"I was still aware of the real environment\",            \n",
    "    \"I was completely captivated by the virtual world\",\n",
    "    \"How real did the virtual world seem to you\",\n",
    "    \"How much did your experience in the virtual environment resemble\",\n",
    "    \"To what extent did the virtual world seem like reality\",\n",
    "    \"The virtual world seemed more realistic than the real world\"\n",
    "]\n",
    "\n",
    "reverse_indices = [2, 3, 6, 8]\n",
    "\n",
    "question_columns = []\n",
    "for phrase in question_phrases:\n",
    "    match = next((col for col in df.columns if phrase in col), None)\n",
    "    if match:\n",
    "        question_columns.append(match)\n",
    "    else:\n",
    "        raise ValueError(f\"Could not find column for phrase: {phrase}\")\n",
    "\n",
    "result = pd.DataFrame()\n",
    "result[\"ParticipantID\"] = df[\"学生ID / StudentID\"]\n",
    "\n",
    "for i, col in enumerate(question_columns):\n",
    "    q_label = f\"Q{i+1}\"\n",
    "    if i in reverse_indices:\n",
    "        result[q_label] = 8 - df[col]\n",
    "    else:\n",
    "        result[q_label] = df[col]\n",
    "\n",
    "result[\"IPQ_TotalScore\"] = result[[f\"Q{i+1}\" for i in range(14)]].sum(axis=1)\n",
    "\n",
    "INV_items = ['Q1', 'Q2', 'Q5', 'Q6', 'Q10']\n",
    "SP_items = ['Q3', 'Q4', 'Q7', 'Q8', 'Q9']\n",
    "REAL_items = ['Q11', 'Q12', 'Q13', 'Q14']\n",
    "\n",
    "INV = df[INV_items].mean(axis=1)\n",
    "SP = df[SP_items].mean(axis=1)\n",
    "REAL = df[REAL_items].mean(axis=1)\n",
    "\n",
    "means = [INV.mean(), SP.mean(), REAL.mean()]\n",
    "errors = [INV.std(ddof=1)/np.sqrt(len(INV)), SP.std(ddof=1)/np.sqrt(len(SP)), REAL.std(ddof=1)/np.sqrt(len(REAL))]\n",
    "\n",
    "labels = ['Involvement', 'Spatial Presence', 'Realism']\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "bars = ax.bar(x, means, yerr=errors, capsize=8, color=['#FECF8D', '#F9A87D', '#DC5F5F'], edgecolor='black')\n",
    "\n",
    "ax.set_ylabel('Mean Rating (1–7)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_title('Mean Ratings of IPQ Subscales')\n",
    "ax.set_ylim(0, 8)\n",
    "\n",
    "for i, data in enumerate([INV, SP, REAL]):\n",
    "    jitter = np.random.normal(loc=0, scale=0.05, size=len(data))\n",
    "    ax.scatter(np.full_like(data, x[i]) + jitter, data, color='black', s=20, alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
